%%
% File: Traffic_Sign_CNN.m
%   Load the tranining and test data sets. Use the convolutional neural
%   network classifier to train and test the model. 
%
% Info:
%   Class: EN.525.670.81 - Machine Learning for Signal Processing
%   Term: Spring 2020
%   Author: Cassie Xia
%

%%
% clear workspace
clear all; close all; clc;

%% 1. Load the training data.
sBasePath = fullfile(fileparts(fullfile(mfilename('fullpath'))),'..','gtsrb-german-traffic-sign/');

sTrainingPath = [sBasePath, 'Train.csv'];

% Find signstrain.mat and signstest.mat
% If not found generate them
curDir = pwd;
filename = [curDir,'/','signstrain.mat'];

if isfile(filename)
    signstrain = load(filename);
else
    % generate matfile
    signstrain = generate_csv2mat(sTrainingPath,filename);
end

%% 2. Load the test data

sTestPath = [sBasePath, 'Test.csv'];

filename = [curDir,'/','signstest.mat'];

if isfile(filename)
    signstest = load(filename);
else
    % generate matfile
    signstest = generate_csv2mat(sTestPath,filename,'imPreProcess',true);
end

% Set train and test data
tr_images = signstrain.A;
tr_labels = signstrain.classes;

test_images = signstest.A;
%test_images = signstest.B;
test_labels = signstest.classes;

% Perform dimensionality reduction
numBasis = 120;
[V, D] = pca_basis(tr_images,numBasis);

% Projections
train_projection = tr_images*V;
test_projection = test_images*V;

% Set train labels for CNN
train_cnn_labels = zeros(length(tr_labels),max(tr_labels)+1);
for i=1:length(tr_labels)
   train_cnn_labels(i,tr_labels(i)+1) = 1; 
end

% Set test labels for CNN
test_cnn_labels = zeros(length(test_labels),max(test_labels)+1);
for i=1:length(test_labels)
   test_cnn_labels(i,test_labels(i)+1) = 1; 
end

%% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 30-Apr-2020 00:47:16
%
% This script assumes these variables are defined:
%
%   train_projection - input data.
%   train_cnn_labels - target data.

x = train_projection';
t = train_cnn_labels';

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
hiddenLayerSize = 70;   % can customize for better results
net = patternnet(hiddenLayerSize, trainFcn);

% Setup Division of Data for Training, Validation, Testing
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% Train the Network
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
e = gsubtract(t,y);
performance = perform(net,t,y);
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);
correctRate = 1-percentErrors;

% View the Network
view(net)

fprintf('CNN Testing Data from Training - PCA Basis: %d Performance: %d CorrectRate: %f ErrorRate: %f \n',...
    numBasis,...
    performance,...
    correctRate, percentErrors);

% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)

% % Deployment
% % Change the (false) values to (true) to enable the following code blocks.
% % See the help for each generation function for more information.
% if (false)
%     % Generate MATLAB function for neural network for application
%     % deployment in MATLAB scripts or with MATLAB Compiler and Builder
%     % tools, or simply to examine the calculations your trained neural
%     % network performs.
%     genFunction(net,'myNeuralNetworkFunction');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a matrix-only MATLAB function for neural network code
%     % generation with MATLAB Coder tools.
%     genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a Simulink diagram for simulation or deployment with.
%     % Simulink Coder tools.
%     gensim(net);
% end

%% Test against testing data
x1 = test_projection';
t1 = test_cnn_labels';
% Test the Network
y1 = net(x1);
e1 = gsubtract(t1,y1);
performance1 = perform(net,t1,y1);
tind1 = vec2ind(t1);
yind1 = vec2ind(y1);
percentErrors1 = sum(tind1 ~= yind1)/numel(tind1);
correctRate1 = 1-percentErrors1;

fprintf('CNN Testing Data from Test - PCA Basis: %d Performance: %d CorrectRate: %f ErrorRate: %f \n',...
    numBasis,...
    performance1,...
    correctRate1, percentErrors1);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Part 2 with Hue Histogram
%  Performance is quite a bit better with the PCA basis
%% Setup

basePath = 'C:/Users/casxi/Google Drive/Documents/JHU/Machine Learning for Signal Processing/Final Project/gtsrb-german-traffic-sign/'; 

% sTrainingPath = [sBasePath, 'Train.csv'];

trainCsv = 'Train.csv';
testCsv = 'Test.csv';
metaCsv = 'Meta.csv';

%% Data Conditioning

% [OPTIONAL]Only use the highest quality training and test images
[trainPaths, trainWidths, trainHeights, trainRoiX1, trainRoiY1, trainRoiX2, trainRoiY2, trainClasses]  = reduce_dataset(basePath, trainCsv, .75, .75);
[testPaths, testWidths, testHeights, testRoiX1, testRoiY1, testRoiX2, testRoiY2, testClasses]  = reduce_dataset(basePath, testCsv, .75, .75);

% [OPTIONAL] Do further histogram equalization?

% [OPTIONAL] Generate new data to reduce class skew

%% Feature Extraction

% Extract Hue Histogram features
train_hue_features = get_hue_histograms(basePath, trainPaths, trainRoiX1, trainRoiY1, trainRoiX2, trainRoiY2, 100);
test_hue_features = get_hue_histograms(basePath, testPaths, testRoiX1, testRoiY1, testRoiX2, testRoiY2, 100);

% trainClasses, testClasses
% Set train labels for Hue Histogram features
train_hh_labels = zeros(length(trainClasses),max(trainClasses)+1);
for i=1:length(trainClasses)
   train_hh_labels(i,trainClasses(i)+1) = 1; 
end

% Set test labels for Hue Histogram features
test_hh_labels = zeros(length(testClasses),max(testClasses)+1);
for i=1:length(testClasses)
   test_hh_labels(i,testClasses(i)+1) = 1; 
end

%% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 01-May-2020 02:02:18
%
% This script assumes these variables are defined:
%
%   train_hue_features - input data.
%   train_hh_labels - target data.

xx = train_hue_features';
tt = train_hh_labels';

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
hiddenLayerSize = 10;   % can customize for better results, more or less similar
neth = patternnet(hiddenLayerSize, trainFcn);

% Setup Division of Data for Training, Validation, Testing
neth.divideParam.trainRatio = 70/100;
neth.divideParam.valRatio = 15/100;
neth.divideParam.testRatio = 15/100;

% Train the Network
[neth,tr] = train(neth,xx,tt);

% Test the Network
yy = neth(xx);
ee = gsubtract(tt,yy);
performance = perform(neth,tt,yy);
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);
correctRate = 1-percentErrors;

% View the Network
view(neth)

fprintf('CNN Testing Data from Training - Hue Histogram Features Performance: %d CorrectRate: %f ErrorRate: %f \n',...
    performance,...
    correctRate, percentErrors);

%% Test against testing data
xx1 = test_hue_features';
tt1 = test_hh_labels';
% Test the Network
yy1 = neth(xx1);
ee1 = gsubtract(tt1,yy1);
performance1 = perform(neth,tt1,yy1);
tind1 = vec2ind(tt1);
yind1 = vec2ind(yy1);
percentErrors1 = sum(tind1 ~= yind1)/numel(tind1);
correctRate1 = 1-percentErrors1;

fprintf('CNN Testing Data from Test - Hue Histogram Features Performance: %d CorrectRate: %f ErrorRate: %f \n',...
    performance1,...
    correctRate1, percentErrors1);

